[{"authors":["admin"],"categories":null,"content":"I am currently a senior hardware engineer in Microsoft Azure Hardware Architecture, working on cloud-scale hardware acceleration for artificial intelligence.\nI earned my PhD in computer architecture from the UC Berkeley EECS department in 2021, with a dissertation titled ``Generator-Based Design of Custom Systems-on-Chip for Numerical Data Analysis\u0026rdquo;. I was supervised by Borivoje Nikolić and Krste Asanović, and affiliated with the ADEPT Lab (formerly ASPIRE), and the Berkeley Wireless Research Center (BWRC).\nI am a recipient of the 2020-2021 Demetri Angelakos Memorial Achievement Award from the UC Berkeley EECS Department, and was active as the co-president and treasurer of the Electrical Engineering Graduate Student Association (EEGSA) in the UC Berkeley EECS Department and as a delegate to the UC Berkeley Graduate Assembly (GA).\nI'm interested in most parts of the digital computing stack, from circuits to software. I believe that the end of Moore's law and the never-ending demand for additional computing resources require us to solve the interesting challenges of distributed, parallel, and heterogeneous computing in an energy efficient manner. These challenges span across the computing stack from the single-core and single-chip level up to clusters of thousands of many-core heterogeneous machines, and require system-level design.\nSpecifically, I've been recently focusing on data-parallel and numerical analysis applications, hardware-software co-design, large-scale distributed clusters, and the trade-offs between general purpose data parallel processors and custom specialized accelerators for emerging machine learning and data-analytics workloads.\nI am a supporter of the open-source hardware movement as an innovation catalyst, and I try to contribute to the RISC-V ecosystem. As part of my PhD, I was a user and developer of the open-source \u0026ldquo;Berkeley ecosystem\u0026rdquo; for agile hardware design developed in the ASPIRE and ADEPT labs. I am a developer of the FireSim and Chipyard projects and was a contributor to the Hurricane/Eagle series of test chips, demonstrating new capabilities in generator-based SoC development.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am currently a senior hardware engineer in Microsoft Azure Hardware Architecture, working on cloud-scale hardware acceleration for artificial intelligence.\nI earned my PhD in computer architecture from the UC Berkeley EECS department in 2021, with a dissertation titled ``Generator-Based Design of Custom Systems-on-Chip for Numerical Data Analysis\u0026rdquo;. I was supervised by Borivoje Nikolić and Krste Asanović, and affiliated with the ADEPT Lab (formerly ASPIRE), and the Berkeley Wireless Research Center (BWRC).","tags":null,"title":"Alon Amid","type":"authors"},{"authors":["Alon Amid","Hasan Genc","Jerry Zhao","Krste Asanovic","Borivoje Nikolic","Yakun Sophia Shao"],"categories":null,"content":"","date":1664668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664668800,"objectID":"bbcd70613d274c0a344d76fad12a4d55","permalink":"/publication/gemmini-controller-wddsa/","publishdate":"2022-10-02T00:00:00Z","relpermalink":"/publication/gemmini-controller-wddsa/","section":"publication","summary":"Deep learning inference and training tasks are often accompanied by additional numerical data analysis tasks such as clustering, dimensionality reduction, data transformation, and linear modeling. While matrix engines are primarily designed with deep neural network workloads in mind, they have also been used to accelerate general-purpose matrix processing workloads. The matrix multiplication components of numerical data analysis workloads vary in matrix shapes, sizes, and layouts compared to deep neural network models. In this wide problem space, subtle static scheduling or system-level effects generate variable memory-latency behavior observed by the accelerator in small matrix size regimes, leading to up to a 30% degradation in accelerator utilization. We observe that minor modifications to a matrix accelerator’s hardware controller can substantially improve the suitability of the accelerator for these problem types, and demonstrate up to a 1.25x improvement in the utilization of a matrix engine on small matrices through hardware-managed static scheduling, and up to a 1.15x improvement through dynamic scheduling and hardware-managed commutative micro-threading, helping improve the utilization of matrix engines for general purpose linear algebra workloads.","tags":null,"title":"Accelerating General-Purpose Linear Algebra on DNN Accelerators","type":"publication"},{"authors":["Hasan Genc","Seah Kim","Alon Amid","Ameer Haj-Ali","Vighnesh Iyer","Pranav Prakash","Jerry Zhao","Daniel Grubb","Harrison Liew","Howard Mao","Albert Ou","Colin Schmidt","Samuel Steffl","John Wright","Ion Stoica","Jonathan Ragan-Kelley","Krste Asanovic","Borivoje Nikolic","Yakun Sophia Shao"],"categories":null,"content":"","date":1638662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638662400,"objectID":"39360dbb53dac676005e5b4d49a5f58c","permalink":"/publication/gemmini-dac/","publishdate":"2021-12-05T00:00:00Z","relpermalink":"/publication/gemmini-dac/","section":"publication","summary":"DNN accelerators are often developed and evaluated in isolation without considering the cross-stack, system-level effects in real-world environments. This makes it difficult to appreciate the impact of System-on-Chip (SoC) resource contention, OS overheads, and programming stack inefficiencies on overall performance/energy-efficiency. To address this challenge, we present Gemmini, an open-source, full-stack DNN accelerator generator. Gemmini generates a wide design-space of efficient ASIC accelerators from a flexible architectural template, together with flexible programming stacks and full SoCs with shared resources that capture system-level effects. Gemmini-generated accelerators have also been fabricated, delivering up to three orders-of-magnitude speedups over high-performance CPUs on various DNN benchmarks.","tags":null,"title":"Gemmini: Enabling Systematic Deep-Learning Architecture Evaluation via Full-Stack Integration","type":"publication"},{"authors":["David Biancolin","Albert Magyar","Sagar Karandikar","Alon Amid","Borivoje Nikolic","Jonathan Bachrach","Krste Asanovic"],"categories":null,"content":"","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625097600,"objectID":"6ce6bd117dc8cbc78c42ee7d3904d523","permalink":"/publication/gg-firesim-micro/","publishdate":"2021-07-01T00:00:00Z","relpermalink":"/publication/gg-firesim-micro/","section":"publication","summary":"Given the complexity of modern systems-on-chip (SoCs), hardware-assisted verification is an integral part of the chip-design process. However, chip designers often need to choose between richly featured but expensive emulation platforms or faster, cheaper, but less debuggable FPGA prototyping solutions. FireSim, an open-source, FPGA-accelerated hardware emulation platform hosted in the public cloud, attempts to accessibly offer the best of both worlds. This article highlights two new FireSim capabilities that help realize this goal: multi-cycle resource optimizations, which can enable an eight-fold increase emulated core count, and FPGA-agnostic support for multi-clock systems. These supplement existing FireSim features which provide a foundation for productive emulation, including a cloud manager to automatically scale out experiments and a rich debug toolkit.","tags":null,"title":"Accessible, FPGA Resource-Optimized Simulation of Multi-Clock Systems in FireSim","type":"publication"},{"authors":null,"categories":null,"content":"","date":1625067000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625067000,"objectID":"76cbc798021f6667405dbf2c9768b190","permalink":"/talk/dissertation-talk/","publishdate":"2021-06-30T15:30:00Z","relpermalink":"/talk/dissertation-talk/","section":"talk","summary":"With the end of Moore's Law and Dennard scaling, the continuous demand for higher computing performance and efficiency is increasingly met through specialization of digital processor implementations. In particular, numerical data processing and machine learning applications incur high computational costs but often have common computational structures, acting as prime targets for hardware customization. Specialization of digital designs is accompanied by substantial non-recurring engineering (NRE) costs, which limit the proliferation of customized designs. This talk presents tools and methodologies for the development of custom systems-on-chip (SoCs) for numerical data analysis applications. An integrated generator-based framework for SoC development is demonstrated through SoC customization and hardware/software co-design for numerical data analysis and machine learning applications. The development of full system support from hardware accelerators through system software leads to the identification of several co-design opportunities for increasing accelerator utility in custom SoCs.","tags":null,"title":"Generator-Based Design of Custom Systems-on-Chips for Numerical Data Analysis","type":"talk"},{"authors":null,"categories":null,"content":"","date":1622224800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622224800,"objectID":"973786ff652870bae6f2f4cafb07dc0d","permalink":"/talk/iscas-2021/","publishdate":"2021-05-28T18:00:00Z","relpermalink":"/talk/iscas-2021/","section":"talk","summary":"The design of computing systems has changed dramatically over the past decade, but most courses in advanced computer architecture remain unchanged. Computer architecture education lies at the intersection between computer science and electrical engineering, with practical exercises in classes based on appropriate levels of abstraction in the computing system design stack. Hardware-centric lab exercises often require broad infrastructure resources and tend to navigate around tedious practical implementation concepts, while software-centric exercises leave a gap between modeling and system implementation implications that students later need to overcome in professional settings. Vertical integration trends in domain-specific compute systems, as well as software-hardware co-design, are often covered in classroom lectures, but are not reflected in laboratory exercises due to complex tooling and simulation infrastructure. We describe our experiences with a joint hardware-software approach to exploring computer architecture concepts in class exercises, by using opensource processor hardware implementations, generator-based hardware design methodologies, and cloud-hosted FPGAs. This approach further enables scaling course enrollment, remote learning and a cross-class collaborative lab ecosystem, creating a connecting thread between computer science and electrical engineering experience-based curricula.","tags":null,"title":"Vertically Integrated Computing Labs Using Open-Source Hardware Generators and Cloud-Hosted FPGAs","type":"talk"},{"authors":["Alon Amid","Albert Ou","Krste Asanovic","Yakun Sophia Shao","Borivoje Nikolic"],"categories":null,"content":"","date":1622160000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622160000,"objectID":"31775ba03c88260eaf378c4574d073bd","permalink":"/publication/chipyard-education-iscas/","publishdate":"2021-05-28T00:00:00Z","relpermalink":"/publication/chipyard-education-iscas/","section":"publication","summary":"The design of computing systems has changed dramatically over the past decade, but most courses in advanced computer architecture remain unchanged. Computer architecture education lies at the intersection between computer science and electrical engineering, with practical exercises in classes based on appropriate levels of abstraction in the computing system design stack. Hardware-centric lab exercises often require broad infrastructure resources and tend to navigate around tedious practical implementation concepts, while software-centric exercises leave a gap between modeling and system implementation implications that students later need to overcome in professional settings. Vertical integration trends in domain-specific compute systems, as well as software-hardware co-design, are often covered in classroom lectures, but are not reflected in laboratory exercises due to complex tooling and simulation infrastructure. We describe our experiences with a joint hardware-software approach to exploring computer architecture concepts in class exercises, by using opensource processor hardware implementations, generator-based hardware design methodologies, and cloud-hosted FPGAs. This approach further enables scaling course enrollment, remote learning and a cross-class collaborative lab ecosystem, creating a connecting thread between computer science and electrical engineering experience-based curricula.","tags":null,"title":"Vertically Integrated Computing Labs Using Open-Source Hardware Generators and Cloud-Hosted FPGAs","type":"publication"},{"authors":null,"categories":null,"content":"","date":1622025600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622025600,"objectID":"36bacde3498ec51d85019e4734900677","permalink":"/talk/adept-summer21/","publishdate":"2021-05-26T10:40:00Z","relpermalink":"/talk/adept-summer21/","section":"talk","summary":"Deep learning models are often accompanied by additional numerical data analysis tasks such as clustering, dimensionality reduction, data transformations, and linear modeling. While matrix engines are primarily designed with deep neural network workloads in mind, they have been demonstrated to be useful for general purpose matrix processing used in such tasks. This talk will describe our process of using an open-source RISC-V SoC design framework (Chipyard) for evaluating the re-use of an edge SoC DNN accelerator for general matrix multiplication workloads. Specifically, we will focus on integration with the relevant software stack (BLAS) and its underlying assumptions, as well as the hardware implications of different arithmetic intensity regimes.","tags":null,"title":"Secondary Use of DNN Accelerators on Edge SoCs (BLAS on Gemmini)","type":"talk"},{"authors":["Jerry Zhao","Abraham Gonzalez","Alon Amid","Sagar Karandikar","Krste Asanovic"],"categories":null,"content":"","date":1616889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616889600,"objectID":"2ec5b85768c0abb677459c57432eb85d","permalink":"/publication/cobra-ispass/","publishdate":"2021-03-28T00:00:00Z","relpermalink":"/publication/cobra-ispass/","section":"publication","summary":"We present COBRA, a framework which enables a realistic hardware-guided methodology for evaluating compositions of hardware branch predictors. COBRA provides a common interface for developing RTL implementations of predictor subcomponents, as well as a predictor composer that automatically generates hardware predictor pipelines from sub-components based on a high-level topological model of a desired algorithm. We demonstrate how COBRA aids in the design and evaluation of diverse predictor architectures and how our hardware-centric approach captures concerns in predictor characterization that are not exposed in software-based algorithm development. Using COBRA, we generate three superscalar pipelined branch predictors with diverse architectures, synthesize them to run at 1 GHz on a commercial FinFET process, integrate them with the open-source BOOM out-of-order core, and evaluate their end-to-end performance on workloads over trillions of cycles. The COBRA generator system has been open-sourced as part of the SonicBOOM out-of-order core.","tags":null,"title":"COBRA: A Framework for Evaluating Compositions of Hardware Branch Predictors","type":"publication"},{"authors":["Nathan Pemberton","Alon Amid"],"categories":null,"content":"","date":1616889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616889600,"objectID":"e21a6e51bb59da204dd17b6445ec4c40","permalink":"/publication/firemarshal-ispass/","publishdate":"2021-03-28T00:00:00Z","relpermalink":"/publication/firemarshal-ispass/","section":"publication","summary":"Reproducibility in the sciences is critical to reliable inquiry, but is often easier said than done. In the computer architecture community, research may require modifying systems from low-level circuits to operating systems and high-level applications. All of these moving parts make reproducible experiments on full-stack systems challenging to design. Furthermore, the computing ecosystem evolves quickly, leading to rapidly obsolete artifacts. This is especially true in the realm of software where applications are often updated on a monthly, or even daily, cadence. In this paper we introduce FireMarshal, a software workload management tool for RISC-V based full-stack hardware development and research. FireMarshal automates workload generation (constructing boot binaries and filesystem images), development (with functional simulation), and evaluation (with cycle-exact RTL simulation). It also ensures, to the extent possible, that the exact same software runs deterministically across all phases of development, providing confidence in correctness and accuracy while minimizing time spent on slow and expensive RTL-level simulation. To ease workload specification, FireMarshal provides sane defaults for common components like firmware and operating systems, freeing users to focus only on project-specific components. Beyond reproducibility, FireMarshal enables continued development of workloads through the use of inheritance, where new workloads can be derived from established and continually updated base workloads. Users communicate their designs through the use of simple JSON configuration files that can be easily version controlled, reused, and shared. In this paper, we describe the design of FireMarshal along with the associated software management methodology for architectural research and development.","tags":null,"title":"FireMarshal: Making HW/SW Co-Design Reproducible and Reliable","type":"publication"},{"authors":null,"categories":null,"content":"","date":1610701200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610701200,"objectID":"ec7541d186d1ea1420359beceed0a2e2","permalink":"/talk/adept-winter21/","publishdate":"2021-01-15T09:00:00Z","relpermalink":"/talk/adept-winter21/","section":"talk","summary":"Continued improvement in computing efficiency requires functional specialization of hardware designs. Agile design methodologies have been proposed to alleviate the increased design costs of customized silicon architectures, but their practice has exposed challenges around complex system-on-chip integration and validation, and technology portability. This talk will present the Chipyard framework, an integrated SoC design, simulation, and implementation environment for specialized compute systems. Chipyard includes configurable, composable, open-source, generator-based IP blocks that can be used across multiple stages of the hardware development flow while maintaining design intent and integration consistency. Through cloud FPGA simulation and rapid ASIC implementation, this work allows for continuous validation of physically realizable customized systems. In this talk, we provide updates on the 1.4 release of Chipyard","tags":null,"title":"Chipyard: An Integrated SoC Design, Simulation, and Implementation Environment - Release 1.4 Updates","type":"talk"},{"authors":null,"categories":null,"content":"","date":1597564800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597564800,"objectID":"6659668cca79cfad26554b23ce5d49b3","permalink":"/talk/chipyard-hotchips2020/","publishdate":"2020-08-16T08:00:00Z","relpermalink":"/talk/chipyard-hotchips2020/","section":"talk","summary":"We present Chipyard - an open-source integrated SoC design, simulation, and implementation environment for specialized RISC-V compute systems. Continued improvement in computing efficiency requires functional specialization of hardware designs. Chipyard includes configurable, composable, open-source, generator-based IP blocks that can be used across multiple stages of the hardware development flow while maintaining design intent and integration consistency. Through cloud-hosted FPGA simulation and rapid ASIC implementation, this work allows for continuous validation of physically realizable customized systems. We demonstrate the capabilities of the Chipyard framework using the BEAGLE test-chip, a heterogenous SoC composed of anapplication class open-source Linux-capable BOOM out-of-order core connected toa vector accelerator and an in-order Rocket corec onnected to a systolic-array machine learning accelerator.","tags":null,"title":"Poster: Chipyard – Integrated Design, Simulation, and Implementation of Custom RISC-V SoCs","type":"talk"},{"authors":["Alon Amid","David Biancolin","Abraham Gonzalez","Daniel Grubb","Sagar Karandikar","Harrison Liew","Albert Magyar","Howard Mao","Albert Ou","Nathan Pemberton","Paul Rigge","Colin Schmidt","John Wright","Jerry Zhao","Jonathan Bachrach","Yakun Sophia Shao","Borivoje Nikolic","Krste Asanovic"],"categories":null,"content":"","date":1595203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595203200,"objectID":"db1e2c36843638f64242699b77c52c42","permalink":"/publication/chipyard-dac/","publishdate":"2020-07-20T00:00:00Z","relpermalink":"/publication/chipyard-dac/","section":"publication","summary":"Continued improvement in computing efficiency requires functional specialization of hardware designs. We present an agile design flow for custom SoCs using the Chipyard framework, an integrated SoC research and implementation environment for custom systems. Chipyard includes configurable, composable, open-source, generator-based designs that can be used across multiple stages of the hardware development flow while maintaining design intent and integration consistency. Through cloud FPGA simulation and rapid ASIC implementation, we demonstrate an iterative agile hardware design cycle which enables continuous validation of physically-realizable customized systems.","tags":null,"title":"Chipyard - An Integrated SoC Research and Implementation Environment","type":"publication"},{"authors":["Colin Schmidt","Alon Amid","John Wright","Ben Keller","Howard Mao","Keertana Settaluri","Jarno Salomaa","Jerry Zhao","Albert Ou","Krste Asanovic","Borivoje Nikolic"],"categories":null,"content":"","date":1595203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595203200,"objectID":"4e94a8e5e042a37efdf7838d7f7043c0","permalink":"/publication/hurricane2-firesim-sscl/","publishdate":"2020-07-20T00:00:00Z","relpermalink":"/publication/hurricane2-firesim-sscl/","section":"publication","summary":"This letter presents a RISC-V System-on-Chip (SoC) with fully integrated switched-capacitor DC–DC converters, adaptive clock generators, mixed-precision floating-point vector accelerators, a 5-Gb/s serial memory interface, and an integrated power management unit (PMU) manufactured in 28-nm FD-SOI. The vector accelerator improves performance and energy per task on a matrix multiplication kernel by 15x and 13x, respectively, and end-to-end performance on machine learning and graph analytical workloads by 8x–12x. Inclusion of microarchitectural counters and fine spatial power-domain granularity facilitate the predictive power-management algorithms that reduce energy per task by 13%–22% compared to the baseline scalar processor. System level simulations of a range of SoC architectural variations with multiple cores and vector accelerators complement the silicon measurements.","tags":null,"title":"Programmable Fine-Grained Power Management and System Analysis of RISC-V Vector Processors in 28-nm FD-SOI","type":"publication"},{"authors":["Alon Amid","David Biancolin","Abraham Gonzalez","Daniel Grubb","Sagar Karandikar","Harrison Liew","Albert Magyar","Howard Mao","Albert Ou","Nathan Pemberton","Paul Rigge","Colin Schmidt","John Wright","Jerry Zhao","Yakun Sophia Shao","Krste Asanovic","Borivoje Nikolic"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"8fa60a91daee85584b5633ed7b3d6f73","permalink":"/publication/chipyard-micro/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/publication/chipyard-micro/","section":"publication","summary":"Continued improvement in computing efficiency requires functional specialization of hardware designs. Agile hardware design methodologies have been proposed to alleviate the increased design costs of custom silicon architectures, but their practice thus far has been accompanied with challenges in integration and validation of complex systems-on-a-chip (SoCs).We present the Chipyard framework, an integrated SoCdesign, simulation, and implementation environment for specialized compute systems. Chipyard includes configurable, composable,open-source,generator-based IP blocks that can be used across multiple stages of the hardware development flow while maintaining design intent and integration consistency. Through cloud-hosted FPGA accelerated simulation and rapid ASIC implementation, Chipyard enables continuous validation of physically realizable customized systems.","tags":null,"title":"Chipyard: Integrated Design, Simulation, and Implementation Framework for Custom SoCs","type":"publication"},{"authors":null,"categories":null,"content":"","date":1584349200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584349200,"objectID":"b11f2f8aa1b36ed8338dd9fd826d9b69","permalink":"/talk/chipyard-firesim-asplos20/","publishdate":"2020-03-16T09:00:00Z","relpermalink":"/talk/chipyard-firesim-asplos20/","section":"talk","summary":"Chipyard is a one-stop shop for generating complex RISC-V SoCs, including in-order and out-of-order processors, uncore components, vector co-processors, and other kinds of accelerators. Users can customize any component of the system and push it through automated ASIC flows (e.g. Hammer), software simulation (e.g. Verilator and VCS), and FPGA-accelerated simulation flows (e.g. FireSim) to enable agile end-to-end computer architecture research with a single re-usable toolchain. FireSim is an open-source FPGA-accelerated simulation framework that can simulate designs built in Chipyard and deploy them to cloud FPGAs, running complex software stacks (e.g. Linux + applications) at 100s of MHz. FireSim simulations exactly and deterministically model Chipyard designs, matching cycle-by-cycle bit-by-bit behavior of the design as if it were taped out in silicon. I/Os like DRAM, UART, and Ethernet are also modeled cycle-accurately, allowing users to model complex systems, including large clusters, beyond the capabilities of test-chips. Together, Chipyard and FireSim bridge the gap between open-hardware and architecture research, automating many common tasks of architecture and VLSI researchers in a single, easy-to-use platform. More details at https://fires.im/asplos-2020-tutorial/","tags":null,"title":"Tutorial on FireSim and Chipyard: End-to-End Architecture Research with RISC-V SoC Generators, Agile Test Chips, and FPGA-Accelerated Simulation on Amazon EC2 F1","type":"talk"},{"authors":null,"categories":null,"content":"","date":1580392800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580392800,"objectID":"e0234c3601fef46e9adc000da8d98271","permalink":"/talk/chipyard-ccc2020/","publishdate":"2020-01-30T14:00:00Z","relpermalink":"/talk/chipyard-ccc2020/","section":"talk","summary":"This tutorial will introduce the Chipyard and FireSim frameworks for the purposes of full-stack architecture exploration and digital system design. The Chipyard framework incorporates multiple open-source Chisel-based generators within the Rocket-Chip SoC generator ecosystem into a single “one-stop-shop” framework enabling design, simulation, and physical design flows. Simulation flows include integration with the open-source Verilator RTL simulator, as well as the FireSim FPGA-Accelerated simulation platform on the AWS public cloud for full-system end-to-end evaluation. The tutorial will demonstrate basic heterogeneous Rocket/BOOM-based SoC system design using the Rocket Chip parameter system with accelerator interfaces, as well as full system evaluation of such SoCs using the various design-cycle flows within the Chipyard framework. In particular, it will spotlight end-to-end HW/SW evaluation using the FireSim FPGA-accelerated simulation framework.","tags":null,"title":"Tutorial: Chipyard and FireSim: End-to-End Architecture Exploration with RISC-V SoC Generators, FPGA-Accelerated Simulation and Agile Test Chips","type":"talk"},{"authors":["Sagar Karandikar","Albert Ou","Alon Amid","Howard Mao","Randy Katz","Borivoje Nikolic","Krste Asanovic"],"categories":null,"content":"","date":1579392000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579392000,"objectID":"46a030686595aa3d295b2d0c771cc4eb","permalink":"/publication/fireperf-asplos/","publishdate":"2020-01-19T00:00:00Z","relpermalink":"/publication/fireperf-asplos/","section":"publication","summary":"Achieving high-performance when developing specialized hardware/software systems requires understanding and improving not only core compute kernels, but also intricate and elusive system-level bottlenecks. Profiling these bottlenecks requires both high-fidelity introspection and the ability to run sufficiently many cycles to execute complex software stacks, a challenging combination. In this work, we enable agile full-system performance optimization for hardware/software systems with FirePerf, a set of novel out-of-band system-level performance profiling capabilities integrated into the open-source FireSim FPGA-accelerated hardware simulation platform. Using out-of-band call stack reconstruction and automatic performance counter insertion, FirePerf enables introspecting into hardware and software at appropriate abstraction levels to rapidly identify opportunities for software optimization and hardware specialization, without disrupting end-to-end system behavior like traditional profiling tools. We demonstrate the capabilities of FirePerf with a case study that optimizes the hardware/software stack of an open-source RISC-V SoC with an Ethernet NIC to achieve 8x end-to-end improvement in achievable bandwidth for networking applications running on Linux. We also deploy a RISC-V Linux kernel optimization discovered with FirePerf on commercial RISC-V silicon, resulting in up to 1.72x improvement in network performance.","tags":null,"title":"FirePerf: FPGA-Accelerated Full-System Hardware/Software Performance Profiling and Co-Design","type":"publication"},{"authors":null,"categories":null,"content":"","date":1578934200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578934200,"objectID":"243091b0dc75e4d1e7baac809f573063","permalink":"/talk/adept-winter20/","publishdate":"2020-01-13T16:50:00Z","relpermalink":"/talk/adept-winter20/","section":"talk","summary":"Continued improvement in computing efficiency requires functional specialization of hardware designs. Agile design methodologies have been proposed to alleviate the increased design costs of customized silicon architectures, but their practice has exposed challenges around complex system-on-chip integration and validation, and technology portability. This talk will present the Chipyard framework, an integrated SoC design, simulation, and implementation environment for specialized compute systems. Chipyard includes configurable, composable, open-source, generator-based IP blocks that can be used across multiple stages of the hardware development flow while maintaining design intent and integration consistency. Through cloud FPGA simulation and rapid ASIC implementation, this work allows for continuous validation of physically realizable customized systems.","tags":null,"title":"Chipyard: An Integrated SoC Design, Simulation, and Implementation Environment","type":"talk"},{"authors":null,"categories":null,"content":"","date":1576108800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576108800,"objectID":"f3c557935f79bdcf2a9b9517527dd076","permalink":"/talk/chipyard-rv-summit19/","publishdate":"2019-12-12T00:00:00Z","relpermalink":"/talk/chipyard-rv-summit19/","section":"talk","summary":"This tutorial will introduce the Chipyard and FireSim frameworks for the purposes of full-stack architecture exploration and digital system design. The Chipyard framework incorporates multiple open-source Chisel-based generators within the Rocket-Chip SoC generator ecosystem into a single “one-stop-shop” framework enabling design, simulation, and physical design flows. Simulation flows include integration with the open-source Verilator RTL simulator, as well as the FireSim FPGA-Accelerated simulation platform on the AWS public cloud for full-system end-to-end evaluation. The tutorial will demonstrate basic heterogeneous Rocket/BOOM-based SoC system design using the Rocket Chip parameter system with accelerator interfaces, as well as full system evaluation of such SoCs using the various design-cycle flows within the Chipyard framework. In particular, it will spotlight end-to-end HW/SW evaluation using the FireSim FPGA-accelerated simulation framework. Presented by Jerry Zhao, Abraham Gonzalez, David Biancolin, Alon Amid and Colin Schmidt","tags":null,"title":"Tutorial: Chipyard and FireSim: End-to-End Architecture Exploration with RISC-V SoC Generators, FPGA-Accelerated Simulation and Agile Test Chips","type":"talk"},{"authors":["Alon Amid","Kiseok Kwon","Amir Gholami","Bichen Wu","Krste Asanovic","Kurt Keutzer"],"categories":null,"content":"","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572566400,"objectID":"bdf4350962dce94f33aec51723a2c82a","permalink":"/publication/dnn-codesign-ibm-jrd/","publishdate":"2019-11-01T00:00:00Z","relpermalink":"/publication/dnn-codesign-ibm-jrd/","section":"publication","summary":"Deep Learning is arguably the most rapidly evolving research area in recent years. As a result, it is not surprising that the design of state-of-the-art deep neural net models often proceeds without much consideration of the latest hardware targets, and the design of neural net accelerators proceeds without much consideration of the characteristics of the latest deep neural net models. Nevertheless, in this article, we show that there are significant improvements available if deep neural net models and neural net accelerators are co-designed. In particular, we show that a co-designed neural net model can yield an improvement of 2.6/8.3× in inference speed and 2.25/7.5× in energy as compared to SqueezeNet/AlexNet, while improving the accuracy of the model. We also demonstrate that a careful tuning of the neural net accelerator architecture to a deep neural net model can lead to a 1.9–6.3× improvement in inference speed.","tags":null,"title":"Co-Design of Deep Neural Nets and Neural Net Accelerators for Embedded Vision Applications ","type":"publication"},{"authors":["Hasan Genc","Ameer Haj-Ali","Vighnesh Iyer","Alon Amid","Howard Mao","John Wright","Colin Schmidt","Jerry Zhao","Albert Ou","Max Banister","Yakun Sophia Shao","Borivoje Nikolic","Ion Stoica","Krste Asanovic"],"categories":null,"content":"","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572566400,"objectID":"ee6001935a960986d178b7a258202a22","permalink":"/publication/gemmini/","publishdate":"2019-11-01T00:00:00Z","relpermalink":"/publication/gemmini/","section":"publication","summary":"Advances in deep learning and neural networks have resulted in rapid development of hardware accelerators that support them. A large majority of ASIC accelerators, however, target a single hardware design point to accelerate the main computational kernels of deep neural networks such as convolutions or matrix multiplication. On the other hand, the spectrum of use-cases for neural network accelerators, ranging from edge devices to cloud, presents a prime opportunity for agile hardware design and generator methodologies. We present Gemmini1 - an open source and agile systolic array generator enabling systematic evaluations of deep-learning architectures. Gemmini generates a custom ASIC accelerator for matrix multiplication based on a systolic array architecture, complete with additional functions for neural network inference. Gemmini runs with the RISC-V ISA, and is integrated with the Rocket Chip System-on-Chip generator ecosystem, including Rocket in-order cores and BOOM out-of-order cores. Through an elaborate design space exploration case study, this work demonstrates the selection processes of various parameters for the use-case of inference on edge devices. Selected design points achieve two to three orders of magnitude speedup in deep neural network inference compared to the baseline execution on a host processor. Gemmini-generated accelerators were used in the fabrication of test systems-on-chip in TSMC 16nm and Intel 22FFL process technologies.","tags":null,"title":"Gemmini: An Agile Systolic Array Generator Enabling Systematic Evaluations of Deep-Learning Architectures","type":"publication"},{"authors":null,"categories":null,"content":"","date":1570838400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570838400,"objectID":"369e2286f8a171fc2f076f3a700e5151","permalink":"/talk/chipyard-firesim-micro19/","publishdate":"2019-10-12T00:00:00Z","relpermalink":"/talk/chipyard-firesim-micro19/","section":"talk","summary":"Chipyard is a one-stop shop for generating complex RISC-V SoCs, including in-order and out-of-order processors, uncore components, vector co-processors, and other kinds of accelerators. Users can customize any component of the system and push it through automated ASIC flows (e.g. Hammer), software simulation (e.g. Verilator and VCS), and FPGA-accelerated simulation flows (e.g. FireSim) to enable agile end-to-end computer architecture research with a single re-usable toolchain. FireSim is an open-source FPGA-accelerated simulation framework that can simulate designs built in Chipyard and deploy them to cloud FPGAs, running complex software stacks (e.g. Linux + applications) at 100s of MHz. FireSim simulations exactly and deterministically model Chipyard designs, matching cycle-by-cycle bit-by-bit behavior of the design as if it were taped out in silicon. I/Os like DRAM, UART, and Ethernet are also modeled cycle-accurately, allowing users to model complex systems, including large clusters, beyond the capabilities of test-chips. Together, Chipyard and FireSim bridge the gap between open-hardware and architecture research, automating many common tasks of architecture and VLSI researchers in a single, easy-to-use platform. More details at https://fires.im/micro-2019-tutorial/","tags":null,"title":"Tutorial on FireSim and Chipyard: End-to-End Architecture Research with RISC-V SoC Generators, Agile Test Chips, and FPGA-Accelerated Simulation on Amazon EC2 F1","type":"talk"},{"authors":["Alon Amid","Albert Ou","Krste Asanovic","Borivoje Nikolic"],"categories":null,"content":"","date":1561161600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561161600,"objectID":"0aaac72a5ed016a1d8f7b99b80d7c3fe","permalink":"/publication/nested-pagerank-carrv/","publishdate":"2019-05-02T00:00:00Z","relpermalink":"/publication/nested-pagerank-carrv/","section":"publication","summary":"Graph processing kernels and sparse-representation linear algebra workloads such as PageRank are increasingly used in machine learning and graph analytics contexts. While data-parallel processing and chip-multiprocessors have both been used in recent years as complementary mitigations to the slowing rate of single-thread performance improvements, they have been used together most effectively on dense data-structure representations as opposed to sparse representations. We present nested-parallelism implementations of PageRank for RISC-V multi-processor Rocket chip SoCs with Hwacha vector architecture accelerators. These software implementations are used for hardware and software design-space exploration using FPGA-accelerated simulation with multiple silicon-proven multi-processor SoC configurations. The design space includes a variety of scalar cores, vector accelerator cores, and cache parameters, as well as multiple software implementations with tunable parallelism parameters. This work shows the benefits of the loop-raking vectorizing technique compared to an alternative vectorizing technique, and presents up to a 14x run-time speedup relative to a parallel-scalar implementation running on the same SoC configuration. A 25x speedup is demonstrated in a dual-tile SoC with dual-lanes-per-tile vector accelerators, compared to a minimal scalar implementation, demonstrating the scalability of the proposed nested-parallelism techniques.","tags":null,"title":"Nested-Parallelism PageRank on RISC-V Vector Multi-Processors","type":"publication"},{"authors":["Sagar Karandikar","David Biancolin","Alon Amid","Nathan Pemberton","Albert Ou","Randy Katz","Borivoje Nikolic","Jonathan Bachrach","Krste Asanovic"],"categories":null,"content":"","date":1561161600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561161600,"objectID":"7cc94b7f2f2b43c87ffcaebdd804512b","permalink":"/publication/firesim-carrv/","publishdate":"2019-05-02T00:00:00Z","relpermalink":"/publication/firesim-carrv/","section":"publication","summary":"The explosive growth in the RISC-V ecosystem has brought about a multitude of open RTL SoC implementations, as well as broad software compatibility, presenting the opportunity to perform computer architecture research with direct impact using real implementations. However, putting these together in a research context with small, agile teams of developers has been challenging due to difficulty maintaining hardware compatibility with complicated software stacks, slow software RTL simulators, and poor introspection, productivity, and modeling-accuracy with FPGA prototyping. While our prior work described FireSim's capabilities as an FPGA-accelerated cycle-exact datacenter simulation platform, in this paper, we delve into the internals of FireSim and walk through a case study simulating a novel hardware accelerator (Hwacha) that shows how a researcher would use FireSim as a tool for rapidly and cycle-exactly modeling their own systems that build on a single-node RISC-V SoC. We discuss how FireSim addresses the challenges of building a reliable, reproducible, and productive RISC-V research environment, including packaging standardized releases of compatible RISC-V software and hardware, automating the process of running cycle-exact simulations on cloud FPGAs that are orders of magnitude faster than any software simulator, and providing debugging tools that allow introspection capabilities not available in FPGA prototypes.","tags":null,"title":"Using FireSim to Enable Agile End-to-End RISC-V Computer Architecture Research","type":"publication"},{"authors":null,"categories":null,"content":"","date":1560643200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560643200,"objectID":"067ea66281ddfd97d6401d470c613b5c","permalink":"/talk/full-sytem-arch-huji19/","publishdate":"2019-06-16T00:00:00Z","relpermalink":"/talk/full-sytem-arch-huji19/","section":"talk","summary":"In this talk, I will describe several research projects developed in the Berkeley Architecture Research group which utilize FPGA-accelerated simulation and open-source hardware, demonstrating the possibilities and accessibility of full-system computer architecture research using these tools and methodologies. FireSim is an easy-to-use, open-source, FPGA-accelerated cycle-accurate hardware simulation platform that runs on Amazon EC2 F1. FireSim automatically transforms and instruments open-hardware designs (e.g. RISC-V Rocket Chip, BOOM, Hwacha, NVDLA, etc.) with the MIDAS framework into fast (10s-100s MHz), deterministic, FPGA-based simulators that enable productive pre-silicon verification and performance validation. FireSim is capable of scaling to simulating thousands of multi-core compute nodes, with optional cycle-accurate network simulation tying them together, enabling cycle-accurate data-center simulation of over 1000 nodes. I will describe how FPGA-accelerated simulation tools can assist in the analysis and co-design of system-level performance issues, specifically in the context of low level operating system interaction with custom hardware implementations such as network interface controllers. Finally, I will demonstrate how FireSim can be used for joint SW/HW design space exploration of multi-core processors with data-parallel vector accelerators, allowing for exploration of nested-parallelism implementations with common parallel programming libraries.","tags":null,"title":"Full-System Computer Architecture Using Open-Source Hardware and FPGA-Accelerated Simulation","type":"talk"},{"authors":null,"categories":null,"content":"","date":1560297600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560297600,"objectID":"d704791d577542aa1b0ddddf511b7835","permalink":"/talk/full-sytem-arch-techion19/","publishdate":"2019-06-12T00:00:00Z","relpermalink":"/talk/full-sytem-arch-techion19/","section":"talk","summary":"In this talk, I will describe several research projects developed in the Berkeley Architecture Research group which utilize FPGA-accelerated simulation and open-source hardware, demonstrating the possibilities and accessibility of full-system computer architecture research using these tools and methodologies. FireSim is an easy-to-use, open-source, FPGA-accelerated cycle-accurate hardware simulation platform that runs on Amazon EC2 F1. FireSim automatically transforms and instruments open-hardware designs (e.g. RISC-V Rocket Chip, BOOM, Hwacha, NVDLA, etc.) with the MIDAS framework into fast (10s-100s MHz), deterministic, FPGA-based simulators that enable productive pre-silicon verification and performance validation. FireSim is capable of scaling to simulating thousands of multi-core compute nodes, with optional cycle-accurate network simulation tying them together, enabling cycle-accurate data-center simulation of over 1000 nodes. I will describe how FPGA-accelerated simulation tools can assist in the analysis and co-design of system-level performance issues, specifically in the context of low level operating system interaction with custom hardware implementations such as network interface controllers. Finally, I will demonstrate how FireSim can be used for joint SW/HW design space exploration of multi-core processors with data-parallel vector accelerators, allowing for exploration of nested-parallelism implementations with common parallel programming libraries.","tags":null,"title":"Full-System Computer Architecture Using Open-Source Hardware and FPGA-Accelerated Simulation","type":"talk"},{"authors":null,"categories":null,"content":"","date":1557446400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557446400,"objectID":"927611af006989bd8cc06c83ebce66f7","permalink":"/talk/pagerank-carrv/","publishdate":"2019-05-10T00:00:00Z","relpermalink":"/talk/pagerank-carrv/","section":"talk","summary":"Graph processing kernels and sparse-representation linear algebra workloads such as PageRank are increasingly used in machine learning and graph analytics contexts. While data-parallel processing and chip-multiprocessors have both been used in recent years as complementary mitigations to the slowing rate of single-thread performance improvements, they have been used together most effectively on dense data-structure representations as opposed to sparse representations. We present nested-parallelism implementations of PageRank for RISC-V multi-processor Rocket chip SoCs with Hwacha vector architecture accelerators. These software implementations are used for hardware and software design-space exploration using FPGA-accelerated simulation with multiple silicon-proven multi-processor SoC configurations. The design space includes a variety of scalar cores, vector accelerator cores, and cache parameters, as well as multiple software implementations with tunable parallelism parameters. This work shows the benefits of the loop-raking vectorizing technique compared to an alternative vectorizing technique, and presents up to a 14x run-time speedup relative to a parallel-scalar implementation running on the same SoC configuration. A 25x speedup is demonstrated in a dual-tile SoC with dual-lanes-per-tile vector accelerators, compared to a minimal scalar implementation, demonstrating the scalability of the proposed nested-parallelism techniques.","tags":null,"title":"Nested-Parallelism PageRank on RISC-V Vector Multi-Processors","type":"talk"},{"authors":null,"categories":null,"content":"","date":1556928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556928000,"objectID":"ef9b232482fa7221c0ca42ea012faf0d","permalink":"/talk/firesim-latchup/","publishdate":"2019-05-04T00:00:00Z","relpermalink":"/talk/firesim-latchup/","section":"talk","summary":"We present FireSim, an easy-to-use, open-source, FPGA-accelerated cycle-accurate hardware simulation platform that runs on Amazon EC2 F1. FireSim automatically transforms and instruments open-hardware designs (e.g. RISC-V Rocket Chip, BOOM, Hwacha, NVDLA, etc.) with the MIDAS framework into fast (10s-100s MHz), deterministic, FPGA-based simulators that enable productive pre-silicon verification and performance validation. To model I/O, FireSim includes synthesizeable and timing-accurate models for standard interfaces like DRAM, Ethernet, UART, and others. By providing a framework to automate the management of FPGA infrastructure, FireSim also lets software developers get a head-start on building software for a novel hardware design, by letting these developers interact with the pre-silicon hardware design as they would a virtual machine. In effect, both hardware and software developers work from a single source of truth: the RTL for the hardware design. Originally developed to simulate new datacenter architectures, FireSim is capable of scaling to simulating thousands of multi-core compute nodes, with an optional cycle-accurate network simulation tying them together. Leveraging AWS EC2 F1, FireSim removes the high capex traditionally involved in large-scale FPGA-based simulation, democratizing access to realistic pre-silicon hardware modeling of new designs. For designs that contain RISC-V SoCs, FireSim also provides compatible Linux distributions (Buildroot, Fedora) and automates the process of building complex workloads on top of these Linux distributions. By harnessing a standardized host platform and providing a large amount of automation/tooling, FireSim drastically simplifies the process of building and deploying large-scale FPGA-based hardware simulations. In this talk, we cover the open-source FireSim framework, explore how users can use and modify the existing designs available in FireSim, and show how users can integrate and measure their own hardware designs. Presented by David Biancolin and Alon Amid","tags":null,"title":"FireSim: Open-Source Easy-to-use FPGA-Accelerated Cycle-Exact Hardware Simulation in the Cloud","type":"talk"},{"authors":["Sagar Karandikar","Howard Mao","Donggyu Kim","David Biancolin","Alon Amid","Dayeol Lee","Nathan Pemberton","Emmanuel Amaro","Colin Schmidt","Aditya Chopra","Qijing Huang","Kyle Kovacs","Borivoje Nikolic","Randy Katz","Jonathan Bachrach","Krste Asanovic"],"categories":null,"content":"","date":1556668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556668800,"objectID":"73eb7bc7594032cd6cd4ef5578b5cb28","permalink":"/publication/firesim-micro/","publishdate":"2019-05-01T00:00:00Z","relpermalink":"/publication/firesim-micro/","section":"publication","summary":"In this article, we present FireSim, an open-source simulation platform that enables fast cycle-exact microarchitectural simulation of large scale-out clusters by combining FPGA-accelerated simulation of silicon-proven RTL designs with scalable, distributed network simulation, running on a public-cloud host platform. By introducing automation and harnessing cloud FPGAs, FireSim provides the usability and productivity of software full-system simulators with the high performance and accuracy of FPGA-accelerated simulation, while adding the unprecedented ability to scale to globally cycle-accurate simulations of thousands of networked nodes. To demonstrate FireSim's scalability, we automatically generate and deploy a target cluster simulation of 1024 3.2-GHz quad-core server nodes, each with 16 GB of DRAM, interconnected by a 200 Gb/s network with low latency, which simulates at a 6.6-MHz processor clock rate (","tags":null,"title":"FireSim: FPGA-Accelerated Cycle-Exact Scale-Out System Simulation in the Public Cloud","type":"publication"},{"authors":null,"categories":null,"content":"","date":1543795200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543795200,"objectID":"e9d5595aac74f663664c1da9a52cecf7","permalink":"/talk/firesim-rv-summit/","publishdate":"2018-12-03T00:00:00Z","relpermalink":"/talk/firesim-rv-summit/","section":"talk","summary":"We present a tutorial for FireSim (https://fires.im), an easy-to-use, open-source, FPGA-accelerated cycle-accurate hardware simulation platform developed at UC Berkeley that runs on Amazon EC2 F1. FireSim automatically transforms and instruments open-hardware designs (e.g. RISC-V Rocket Chip and BOOM) using the MIDAS framework into fast, deterministic, FPGA-based simulators that enable productive pre-silicon verification and performance validation. By providing a framework to automate the management of FPGA infrastructure, FireSim also lets software developers get a head-start on building software for a novel hardware design, by letting these developers interact with the pre-silicon hardware design as they would a virtual machine. In effect, both hardware and software developers work from a single source of truth: the RTL for the hardware design. Leveraging AWS EC2 F1, FireSim removes the high capex and management complexity traditionally involved in large-scale FPGA-based simulation, democratizing access to realistic pre-silicon hardware modeling of new designs. In this half-day tutorial, we cover the open-source FireSim framework, explore how users can use and modify the existing designs available in FireSim, and show how users can integrate and measure their own hardware designs. Presented by Sagar Karandikar, David Biancolin and Alon Amid","tags":null,"title":"Tutorial: Easy-to-use, FPGA-Accelerated Hardware Simulation of RISC-V Hardware Designs with FireSim on Amazon EC2 F1","type":"talk"},{"authors":null,"categories":null,"content":"","date":1542153600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542153600,"objectID":"d6cbfc3105d322783142855df6e5019a","permalink":"/talk/firesim-ccc/","publishdate":"2018-11-14T00:00:00Z","relpermalink":"/talk/firesim-ccc/","section":"talk","summary":"We present an intensive session for FireSim (https://fires.im), an easy-to-use, open-source, FPGA-accelerated cycle-accurate hardware simulation platform developed at UC Berkeley that runs on Amazon EC2 F1. FireSim automatically transforms and instruments open-hardware designs (e.g. RISC-V Rocket Chip and BOOM) using the MIDAS framework into fast, deterministic, FPGA-based simulators that enable productive pre-silicon verification and performance validation. By providing a framework to automate the management of FPGA infrastructure, FireSim also lets software developers get a head-start on building software for a novel hardware design, by letting these developers interact with the pre-silicon hardware design as they would a virtual machine. In effect, both hardware and software developers work from a single source of truth: the RTL for the hardware design. Leveraging AWS EC2 F1, FireSim removes the high capex and management complexity traditionally involved in large-scale FPGA-based simulation, democratizing access to realistic pre-silicon hardware modeling of new designs. In this half-day tutorial, we cover the open-source FireSim framework, explore how users can use and modify the existing designs available in FireSim, and show how users can integrate and measure their own hardware designs. Presented by Sagar Karandikar, David Biancolin and Alon Amid","tags":null,"title":"FireSim Intensive","type":"talk"},{"authors":["Kiseok Kwon","Alon Amid","Amir Gholami","Bichen Wu","Krste Asanovic","Kurt Keutzer"],"categories":null,"content":"","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527811200,"objectID":"794d3ba397537bb7fe7e8ee4c791cf57","permalink":"/publication/dnn-codesign-dac/","publishdate":"2018-06-01T00:00:00Z","relpermalink":"/publication/dnn-codesign-dac/","section":"publication","summary":"Deep Learning is arguably the most rapidly evolving research area in recent years. As a result it is not surprising that the design of state-of-the-art deep neural net models proceeds without much consideration of the latest hardware targets, and the design of neural net accelerators proceeds without much consideration of the characteristics of the latest deep neural net models. Nevertheless, in this paper we show that there are significant improvements available if deep neural net models and neural net accelerators are co-designed","tags":null,"title":"Co-Design of Deep Neural Nets and Neural Net Accelerators for Embedded Vision Applications ","type":"publication"},{"authors":["Sagar Karandikar","Howard Mao","Donggyu Kim","David Biancolin","Alon Amid","Dayeol Lee","Nathan Pemberton","Emmanuel Amaro","Colin Schmidt","Aditya Chopra","Qijing Huang","Kyle Kovacs","Borivoje Nikolic","Randy Katz","Jonathan Bachrach","Krste Asanovic"],"categories":null,"content":"","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527811200,"objectID":"6aa6f6c35e5754c9e4ce6ec5ba6863e0","permalink":"/publication/firesim-isca/","publishdate":"2018-06-01T00:00:00Z","relpermalink":"/publication/firesim-isca/","section":"publication","summary":"We present FireSim, an open-source simulation platform that enables cycle-exact microarchitectural simulation of large scale-out clusters by combining FPGA-accelerated simulation of silicon-proven RTL designs with a scalable, distributed network simulation. Unlike prior FPGA-accelerated simulation tools, FireSim runs on Amazon EC2 F1, a public cloud FPGA platform, which greatly improves usability provides elasticity, and lowers the cost of large-scale FPGAbased experiments. We describe the design and implementation of FireSim and show how it can provide sufficient performance to run modern applications at scale, to enable true hardware-software co-design. As an example, we demonstrate automatically generating and deploying a target cluster of 1,024 3.2 GHz quad-core server nodes, each with 16 GB of DRAM, interconnected by a 200 Gbit/s network with 2 microsecond latency, which simulates at a 3.4 MHz processor clock rate (less than 1,000x slowdown over real-time). In aggregate, this FireSim instantiation simulates 4,096 cores and 16 TB of memory, runs ˜14 billion instructions per second, and harnesses 12.8 million dollars worth of FPGAs—at a total cost of only ˜$100 per simulation hour to the user. We present several examples to show how FireSim can be used to explore various research directions in warehouse-scale machine design, including modeling networks with high-bandwidth and lowlatency, integrating arbitrary RTL designs for a variety of commodity and specialized datacenter nodes, and modeling a variety of datacenter organizations, as well as reusing the scaleout FireSim infrastructure to enable fast, massively parallel cycle-exact single-node microarchitectural experimentation.","tags":null,"title":"FireSim: FPGA-Accelerated Cycle-Exact Scale-Out System Simulation in the Public Cloud","type":"publication"},{"authors":["Alon Amid","Borivoje Nikolic"],"categories":null,"content":"","date":1508716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508716800,"objectID":"9a7397c72743f7f22e9844ea83a64950","permalink":"/publication/preventing-babel/","publishdate":"2017-10-23T00:00:00Z","relpermalink":"/publication/preventing-babel/","section":"publication","summary":"Throughout the history of computers, there has been a proliferation of new programming languages. Programmers have a variety of language choices for application or system development. Many languages have differing constructs, syntax rules, and development environments, which impede the productivity of programmers using a diverse language set. With the renewed interest in Domain Specific Languages (DSL), we argue that further emphasis should be put on common core constructs and syntax during the design and evaluation of a new language. We believe common base languages will improve programmers' productivity, and allow the development of a strong supporting ecosystem of programming systems.","tags":null,"title":"Preventing Babel: Rectifying the Trend of Programming Language Divergence","type":"publication"},{"authors":null,"categories":null,"content":"","date":1508716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508716800,"objectID":"a474a285ee9bae05ec587921f7299de8","permalink":"/talk/plateau17/","publishdate":"2017-10-23T00:00:00Z","relpermalink":"/talk/plateau17/","section":"talk","summary":"Throughout the history of computers, there has been a proliferation of new programming languages. Programmers have a variety of language choices for application or system development. Many languages have differing constructs, syntax rules, and development environments, which impede the productivity of programmers using a diverse language set. With the renewed interest in Domain Specific Languages (DSL), we argue that further emphasis should be put on common core constructs and syntax during the design and evaluation of a new language. We believe common base languages will improve programmer productivity, and allow the development of a strong supporting ecosystem of programming systems.","tags":null,"title":"Preventing Babel: Rectifying the Trend of Programming Language Divergence","type":"talk"},{"authors":null,"categories":null,"content":"","date":1498089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498089600,"objectID":"fc930705c32699528966b88cca84db40","permalink":"/talk/graphchip/","publishdate":"2017-06-22T00:00:00Z","relpermalink":"/talk/graphchip/","section":"talk","summary":"Graph processing has been a recent topic of interest in the high performance computing and systems community in the context of data analytics. Graph processing presents difficulties in data-level parallelism and data-layout, which depend on the graph structure. In this talk, I will describe our current process of designing a RISC-V processor, with the purpose of enhancing graph analytics. I will describe insights discovered during this design process, the hardware challenges of graph processing, and what role do high level frameworks play in this design.","tags":null,"title":"Designing a RISC-V Graph Processor - Challenges and Insights","type":"talk"},{"authors":null,"categories":null,"content":"","date":1497398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497398400,"objectID":"c4a9f7cf398159ce0fceb82e82b78473","permalink":"/talk/aspire-summer17/","publishdate":"2017-06-14T00:00:00Z","relpermalink":"/talk/aspire-summer17/","section":"talk","summary":"Graph processing has been a recent topic of interest in the high performance computing and systems community in the context of data analytics. Graph processing presents difficulties in data-level parallelism and data-layout, which depend on the graph structure. In this talk, I will describe our current process of designing an energy efficient graph processor, with the purpose of enhancing graph analytics. I will describe insights discovered during this design process, the hardware challenges of graph processing, and what role do high level frameworks play in this design.","tags":null,"title":"Graph Processing - Efficient Acceleration of Graphs at Low Energy","type":"talk"},{"authors":["Vijayaraghavan Varadharajan","Alon Amid","Sudhanshu Rai"],"categories":null,"content":"","date":1450224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450224000,"objectID":"30af548f222c39c3eb3dd781994f673c","permalink":"/publication/rc-abac-infosys/","publishdate":"2015-12-16T00:00:00Z","relpermalink":"/publication/rc-abac-infosys/","section":"publication","summary":"As network speed and storage capacities are rising faster and higher, the remote storage and 'cloud' concept is gaining momentum and is becoming increasingly popular with personal users as well as business users. At the same time, privacy awareness and business confidentially are important factors in every cloud and data sharing decision. For these and other reasons, the concept of access control models was developed in order to present complete solutions for privacy and confidentiality control in modern systems. Various access controls methodologies have been suggested in the literature, each simplifying and providing flexibility to previous methods. In this paper we will focus on two main methods which are Role Based Access Control (RBAC) and Attribute Based Access Control (ABAC). We will discuss the benefits and drawbacks of each of them, and therefore the need for a novel approach that combines the benefits of these two techniques. We are proposing a different hybrid model and justify how our suggested model and present why we think our suggested model (Policy RC-ABAC) will be more beneficiary in relation to a specific set of needs focusing on flexibility and auditability.","tags":null,"title":"Policy based Role Centric Attribute Based Access Control Model (Policy RC-ABAC)","type":"publication"}]